{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0594553",
   "metadata": {},
   "source": [
    "# Animated plots in Jupyter sessions with the modern Jupyter flavors, specifically JupyterLab and Jupyter Notebook 7+, served via the MyBinder.org system\n",
    "\n",
    "At present, launches of this notebook into MyBinder-served sessions will open in JupyterLab orJupyter Notebook 7+. Both of these are, at present, built upon JupyterLab components.  \n",
    "(If your Jupyter interface is based on NbClassic or Jupyter Notebook 6.4 or earlier, see [here](https://github.com/fomightez/animated_matplotlib_classic-binder).)  \n",
    "Not sure what flavor of Jupyter tech you are using for your notebooks, then see ['Quickly Navigating the tech of the Jupyter ecosystem post-2023'](https://gist.github.com/fomightez/e873947b502f70388d82644b17196279).  \n",
    "In particular, see [the '**Modern JupyterLab vs. Jupyter Notebook 7+**' section of 'Quickly Navigating the tech of the Jupyter ecosystem post-2023'](https://gist.github.com/fomightez/e873947b502f70388d82644b17196279#modern-jupyterlab-vs-jupyter-notebook-7) if you are trying to determine which of the modern flavors you are using.  \n",
    "\n",
    "If you want to switch flavors and you opened in a MyBinder-served session from the repo:  \n",
    "If you are presently in JupyterLab, edit **close to the end of this url** of this page to remove `lab`. For example, `https://hub.ovh2.mybinder.org/user/fomightez-anima-tplotlib-binder-hc7q3ptr/lab/tree/index.ipynb` would become `https://hub.ovh2.mybinder.org/user/fomightez-anima-tplotlib-binder-hc7q3ptr/tree/index.ipynb`.  \n",
    "\n",
    "If you are presently in Jupyter Notebook 7+, edit **close to the end of this url** of this page to add `lab` in front of `tree`. For example, `https://hub.ovh2.mybinder.org/user/fomightez-anima-tplotlib-binder-hc7q3ptr/tree/index.ipynb` would become `https://hub.ovh2.mybinder.org/user/fomightez-anima-tplotlib-binder-hc7q3ptr/lab/tree/index.ipynb` by the insertion of `lab` into the URL. \n",
    "\n",
    "This notebook started out as [this gist on animated plot approaches that worked in JupyterLab](https://gist.github.com/fomightez/e7e70099da1fea17b5e012d79f1d9d30), that was a companion to [the content that now comprises my repo 'animated_matplotlib_classic-binder'](https://github.com/fomightez/animated_matplotlib_classic-binder), and now has been expanded and improved as JupyterLab and Jupyter Notebook 7+ are the currrent centerpieces of the Jupyter ecosystem.\n",
    "\n",
    "#### The Approaches\n",
    "\n",
    "Probably the most established approach that works in JupyterLab and Jupyter Notebook 7+, is the use of Matplotlib's `animation.FuncAnimation()`.\n",
    "However, the other approaches are illustrated first here because the Matplotlib's `animation.FuncAnimation()` involves making a setting to the backend and I want to be sure to illustrate that the other options don't need that. Feel free to skip on ahead to the the demontrations involving Matplotlib's `animation.FuncAnimation()`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf43444-81a1-4766-b3ae-62fad33bce71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b10d804a-a9b8-411b-912d-60217a3aa2b4",
   "metadata": {},
   "source": [
    "## Use of `clear_output()` in conjunction with a delay\n",
    "\n",
    "This approach has the important feature it works in both the classic notebook interface and the modern flavors of Jupyter **without requiring any change to the code**.\n",
    "\n",
    "Here's the basic version of this approach of using `clear_output()`, adapted from [this StackOveflow Answer](https://stackoverflow.com/a/52672859/8508004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51624b-874c-41ff-87c0-a34ecf0e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def live_plot(data_dict, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for label,data in data_dict.items():\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show()\n",
    "    time.sleep(0.15) # extend delay between adding next frame in animation\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "for i in range(30):\n",
    "    data['foo'].append(np.random.random())\n",
    "    data['bar'].append(np.random.random())\n",
    "    data['baz'].append(np.random.random())\n",
    "    live_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41324268",
   "metadata": {},
   "source": [
    "\n",
    "The more fleshed out demo of this approach builds on the Jupyter notebook with related code that can be viewed [here](https://nbviewer.org/gist/fomightez/f539a3770f2f3287bf12de2d2a549e3a).  \n",
    " \n",
    "For the more fleshed out demo, first `torchflow` needs to be installed.  \n",
    "Go ahead and run that below to get the final preparation of the environment out of the way. This will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5e67d-5d16-4520-9e79-a44021dbc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39464cc-d504-469b-a7fa-db695996de34",
   "metadata": {},
   "source": [
    "Restart the kernel after running that cell and then try running the cell below.  \n",
    "**With that preparation complete**, continue on to examine and run this method..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929755b-ade1-4087-a32b-1ae93b6f87fa",
   "metadata": {},
   "source": [
    "In a previous notebook using `fig.canvas.draw()` to reset the image each round, which only works in the older, classic notebook interface ([here](https://nbviewer.org/gist/fomightez/f539a3770f2f3287bf12de2d2a549e3a)), the data was collected first and then the collected data used to plot using `fig.canvas.draw()` to reset the image each round. Here, pause is built in to make sure the animation steps through adding showing each next segment with time in between instead of just quickly blinking through doing that too fast to really see and just displaying the last step.    \n",
    "In addition to the extra delay, the `live_plot()` function that handles updating the plot with each round uses IPython's display control to clear the output with each frame using `clear_output()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/a/52672859/8508004 to help with https://stackoverflow.com/q/75017358/8508004\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "\n",
    "def live_plot(data_dict, figsize=(12,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    #plt.plot(data_dict[\"steps\"],data_dict[\"r\"] , 'r-', label = \"real\")\n",
    "    #plt.plot(data_dict[\"steps\"],data_dict[\"b\"] , 'b-', label = \"prediction\")\n",
    "    for i,_ in enumerate(data_dict[\"steps\"]):\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"r\"][i]) , 'r-', )\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"b\"][i]) , 'b-', )\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show()\n",
    "    time.sleep(0.2) # extend delay between adding next frame in animation\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "    \n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "TIME_STEP = 10      # rnn time step\n",
    "INPUT_SIZE = 1      # rnn input size\n",
    "LR = 0.02           # learning rate\n",
    "\n",
    "# data\n",
    "steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor\n",
    "x_np = np.sin(steps)\n",
    "y_np = np.cos(steps)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,     # rnn hidden unit\n",
    "            num_layers=1,       # number of rnn layer\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "\n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "\n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # outs = outs.view(-1, TIME_STEP, 1)\n",
    "        # return outs, h_state\n",
    "        \n",
    "        # or even simpler, since nn.Linear can accept inputs of any dimension \n",
    "        # and returns outputs with same dimension except for the last\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "h_state = None      # for initial hidden state\n",
    "\n",
    "for step in range(100):\n",
    "    start, end = step * np.pi, (step+1)*np.pi   # time range\n",
    "    # use sin predicts cos\n",
    "    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32, endpoint=False)  # float32 for converting torch FloatTensor\n",
    "    x_np = np.sin(steps)\n",
    "    y_np = np.cos(steps)\n",
    "\n",
    "    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])    # shape (batch, time_step, input_size)\n",
    "    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])\n",
    "\n",
    "    prediction, h_state = rnn(x, h_state)   # rnn output\n",
    "    # !! next step is important !!\n",
    "    h_state = h_state.data        # repack the hidden state, break the connection from last iteration\n",
    "\n",
    "    loss = loss_func(prediction, y)         # calculate loss\n",
    "    optimizer.zero_grad()                   # clear gradients for this training step\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients\n",
    "\n",
    "    # plotting\n",
    "    data['steps'].append(list(steps))\n",
    "    data['r'].append(y_np.flatten())\n",
    "    data['b'].append(prediction.data.numpy().flatten())\n",
    "    live_plot(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c38194-769d-4f75-bf08-272361ee706e",
   "metadata": {},
   "source": [
    "The source of that approach suggested:\n",
    ">\"make sure you have a few cells below the plot, otherwise the view snaps in place each time the plot is redrawn.\"\n",
    "\n",
    "Before getting to the most established way of performing animations in the modern interfaces, there's another that I've come across."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de75fb-4cf5-4524-bd20-d9a1e709065e",
   "metadata": {},
   "source": [
    "## Use of Ipywidget's Play (Animation) Widget combined with the plotting under control of Ipywidget's `interact()`\n",
    "\n",
    "This comes from [here](https://stackoverflow.com/q/76212356/8508004) and relies on [Play (Animation) Widget](https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html#play-animation-widget) in conjunction with ipywidget's `interact()`, and [was part of the original content in my original animation plots repo](https://nbviewer.org/github/fomightez/animated_matplotlib_classic-binder/blob/master/Play_Animation_Widget.ipynb) & I noticed it worked in JupyterLab.  \n",
    "Hence, this approach has the important feature it works in both the classic notebook interface and the modern flavors of Jupyter **without requiring any change to the code**.\n",
    "\n",
    "Run the following cell and then press the '`Play`' button in the upper left side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6491171-1f1e-48ed-a08a-f3879da6676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/q/76212356/8508004\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def theta(t):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax  = plt.axes(projection = \"3d\")\n",
    "    z   = np.linspace(0, t, 500)\n",
    "    x   = np.sin(z)\n",
    "    y   = np.cos(z)\n",
    "    ax.plot3D(x, y, z, 'red')\n",
    "    plt.show()\n",
    "    \n",
    "widgets.interact(theta, t = widgets.Play(min=0, max = 15, interval = 200), continuous_update = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e276b3-01ab-4292-94c9-cd444c66e3d8",
   "metadata": {},
   "source": [
    "What follows next is the probably the most established way of performing animations in the modern interfaces.\n",
    "\n",
    "The ones abov can cause snapping each time the plot is redrawn. And the one below using, Matplotlib's `animation.FuncAnimation()` doesn't make the notebook jumpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905249ff-f537-44c5-90cd-950f1fdc8309",
   "metadata": {},
   "source": [
    "## Use of Matplotlib's `animation.FuncAnimation()`\n",
    "\n",
    "Note that one of the main features of this approach is that it is nearly universal. Very little alteration is necessary to make the exact same code work in the classic notebook interface.\n",
    "\n",
    "Note that to use this it is important that `ipympl` be installed.  \n",
    "With that installed, then the backend is set with `%matplotlib ipympl`.\n",
    "\n",
    "Here is a simple example, I also feature in the classic interface demo notebook; this code sligthly modified from [here](https://stackoverflow.com/a/28077104/8508004) works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cea0b-7c4d-4ddb-b2a4-21e6520dfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(x, y, color='k')\n",
    "\n",
    "def update(num, x, y, line):\n",
    "    line.set_data(x[:num], y[:num])\n",
    "    line.axes.axis([0, 10, 0, 1])\n",
    "    line.axes.set_ylim(-1.1,1.1)\n",
    "    return line,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, len(x), fargs=[x, y, line],\n",
    "                              interval=25, blit=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814912ed-b73a-48f5-9696-dfa1ccf6ab62",
   "metadata": {},
   "source": [
    "Note that it looks a lot like the style of interactive widget you get when you use `%matplotlib notebook` in the classic Jupyter interface. (However, in that interface you could hit the blur button that was in the upper rigth to stop it. I'm not seeing the stop button for this one, and so far even stopping the kernel doesn't work as it keeps running and the kernel keeps blinking as active as it does continue to run. So far, restarting the kernel by one of the various options under the '`Kernel`' menu seems to be the only way I've found.)\n",
    "\n",
    "Here is another example, adapted from [here](https://discourse.jupyter.org/t/matplotlib-animation-not-appearing-in-jupyter-notebook/24938/3?u=fomightez)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a7b8c-029b-4cdc-a255-75537b980a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "stepsize = 0.5\n",
    "num_steps = 20\n",
    "num_trials = 5\n",
    "\n",
    "final_position = []\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    pos = np.array([0, 0])\n",
    "    path = []\n",
    "    for i in range(num_steps):\n",
    "        pos = pos + np.random.normal(0, stepsize, 2)\n",
    "        path.append(pos)\n",
    "    final_position.append(np.array(path))\n",
    "    \n",
    "x = [final_position[i][:,0] for i in range(len(final_position))]\n",
    "y = [final_position[j][:,1] for j in range(len(final_position))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot()\n",
    "fig.subplots_adjust(left=0.1, right=0.85)\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "def animate(frame):\n",
    "    step_num = frame % (num_steps)\n",
    "    trial_num = frame//(num_steps)\n",
    "    color = cmap(trial_num % 10)\n",
    "    if step_num == num_steps-1:\n",
    "        label = f\"Trial = {trial_num+1}\"\n",
    "    else:\n",
    "        label = None\n",
    "    ax.plot(x[trial_num][:step_num], y[trial_num][:step_num], color = color, ls = '-',linewidth = 0.5,\n",
    "            marker = 'o', ms = 8, mfc = color, mec ='k', zorder = trial_num, label = label)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f\"Number of trials = {trial_num+1} \\nNumber of steps = {step_num+1}\")  \n",
    "    if step_num == num_steps-1:\n",
    "        ax.legend(fontsize=10, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "fig.suptitle(f\"2D random walk simulation for {num_steps} steps over {num_trials} trials.\")\n",
    "ani = FuncAnimation(fig, animate, frames= np.arange(0, (num_steps * num_trials)), interval = 100, repeat = False)\n",
    "ani;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c92af2-9013-4003-b12b-dc106fa1964a",
   "metadata": {},
   "source": [
    "#### Demo of the Torchflow one that used `clear_output()` above adpated to  Matplotlib's `animation.FuncAnimation()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5d83c-d92b-46e8-b0e6-3d7d203a4226",
   "metadata": {},
   "source": [
    "Now that I pulled [the original code](https://stackoverflow.com/q/75017358/8508004) apart enough above (the one involving torchflow) to realize each is a segment and implemented a couple approaches, I also wondered if could use the method with Matplotlib's `animation.FuncAnimation()` with associated widget controller that is illustrated at the bottom of [here](https://nbviewer.org/github/fomightez/animated_matplotlib-binder/blob/master/index.ipynb) (and that I had used to answer [here](https://stackoverflow.com/a/75009196/8508004), recently) to make something that also would work in JupyterLab. (**Note it is not all animations methods involving `FuncAnimation()` that work in JupyterLab**, see [here](https://stackoverflow.com/a/73451172/8508004) for one that only works in classic notebook at this time. The widget is key.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f21d4-1724-4538-9525-6efdf42224c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "import collections\n",
    "import time\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = plt.axes(xlim=(0, 320), ylim=(-1.75, 1.75))\n",
    "lineplot, = ax.plot([], [], \"r-\")\n",
    "lineplot2, = ax.plot([], [], \"b-\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "TIME_STEP = 10      # rnn time step\n",
    "INPUT_SIZE = 1      # rnn input size\n",
    "LR = 0.02           # learning rate\n",
    "\n",
    "# data\n",
    "steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor\n",
    "x_np = np.sin(steps)\n",
    "y_np = np.cos(steps)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,     # rnn hidden unit\n",
    "            num_layers=1,       # number of rnn layer\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "\n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "\n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # outs = outs.view(-1, TIME_STEP, 1)\n",
    "        # return outs, h_state\n",
    "        \n",
    "        # or even simpler, since nn.Linear can accept inputs of any dimension \n",
    "        # and returns outputs with same dimension except for the last\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "h_state = None      # for initial hidden state\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "    \n",
    "def init():\n",
    "    global h_state, data \n",
    "    lineplot.set_data([], [])\n",
    "    lineplot2.set_data([], [])\n",
    "    data = collections.defaultdict(list)\n",
    "    return lineplot, #return [lineplot] also works like in https://nbviewer.org/github/raphaelquast/jupyter_notebook_intro/blob/master/jupyter_nb_introduction.ipynb#pre-render-animations-and-export-to-HTML\n",
    "\n",
    "def animate(i):\n",
    "    global h_state, data \n",
    "    step = i\n",
    "    start, end = step * np.pi, (step+1)*np.pi   # time range\n",
    "    # use sin predicts cos\n",
    "    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32, endpoint=False)  # float32 for converting torch FloatTensor\n",
    "    x_np = np.sin(steps)\n",
    "    y_np = np.cos(steps)\n",
    "\n",
    "    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])    # shape (batch, time_step, input_size)\n",
    "    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])\n",
    "\n",
    "    prediction, h_state = rnn(x, h_state)   # rnn output\n",
    "    # !! next step is important !!\n",
    "    h_state = h_state.data        # repack the hidden state, break the connection from last iteration\n",
    "\n",
    "    loss = loss_func(prediction, y)         # calculate loss\n",
    "    optimizer.zero_grad()                   # clear gradients for this training step\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients\n",
    "\n",
    "    # plotting\n",
    "    data['steps'].append(list(steps))\n",
    "    data['r'].append(y_np.flatten())\n",
    "    data['b'].append(prediction.data.numpy().flatten())\n",
    "    #lineplot.set_data([x], [y])\n",
    "    #lineplot2.set_data([x], [z])\n",
    "    lineplot.set_data(data[\"steps\"],data[\"r\"])\n",
    "    lineplot2.set_data(data[\"steps\"],data[\"b\"])\n",
    "    '''\n",
    "    for i,_ in enumerate(data_dict[\"steps\"]):\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"r\"][i]) , 'r-', )\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"b\"][i]) , 'b-', )\n",
    "    '''\n",
    "    return [lineplot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                           frames=100, interval=20, blit=True)\n",
    "anim;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f64b8-d473-4798-b4da-a6f162ee7bea",
   "metadata": {},
   "source": [
    "#### Use of Matplotlib's `animation.FuncAnimation()` with a player controller widget for the frames\n",
    "\n",
    "If you can also make the animations output as a animation made of frames, and this works in JupyterLab and Jupyter Notebook 7+. It provides a player controll widget with a slider for fine tuning of the frame in view and so it can be a nice feature. \n",
    "**A exceptional quality of the animations produced with such a controller is that the animations remain working and controllable with the widget when the 'static' verisons of the saved notebook file are viewed in nbviewer.\n",
    "\n",
    "(See the bottom of [here](https://nbviewer.org/github/fomightez/animated_matplotlib_classic-binder/blob/master/index.ipynb) for where this was originally utilized and described in more detail. I've tried to transfer much if it to here; however, I may have not entirely done that yet. I know my main original source of the ralited information was [a post by Louis Tiao](https://web.archive.org/web/20230330131423/http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/).)\n",
    "\n",
    "Below is a demo from [here](https://gist.github.com/fomightez/e89bc19ec31d8ad1de1b8071c659e684) that uses that. When it shows up hit the 'play' button to play it or slide the slider to pick a frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e7078-b6ac-413b-b69b-b1f814635743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.ioff() #needed so the second time you run it you get only single plot\n",
    "plt.style.use('seaborn-v0_8-pastel')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 4), ylim=(-2, 2))\n",
    "lineplot, = ax.plot([], [], lw=3)\n",
    "    \n",
    "def init():\n",
    "    lineplot.set_data([], [])\n",
    "    return lineplot, #return [lineplot] also works like in https://nbviewer.org/github/raphaelquast/jupyter_notebook_intro/blob/master/jupyter_nb_introduction.ipynb#pre-render-animations-and-export-to-HTML\n",
    "\n",
    "def animate(i):\n",
    "    x = np.linspace(0, 4, 1000)\n",
    "    y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "    lineplot.set_data([x], [y])\n",
    "    return [lineplot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                           frames=200, interval=20, blit=True)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8354af3-40a0-43eb-876b-e4dc2bf0fcc7",
   "metadata": {},
   "source": [
    "More use of widget with player slider controller:  \n",
    "Here is each of the above demos made in turn in that style. Note, really subtle changes only need be made at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245d8ae-cbc4-44e1-9f9e-2b5a086a8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML, display\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.ioff() #needed so the second time you run it you get only single plot\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(x, y, color='k')\n",
    "\n",
    "def update(num, x, y, line):\n",
    "    line.set_data(x[:num], y[:num])\n",
    "    line.axes.axis([0, 10, 0, 1])\n",
    "    line.axes.set_ylim(-1.1,1.1)\n",
    "    return line,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, len(x), fargs=[x, y, line],\n",
    "                              interval=25, blit=True)\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5182a6-38b7-41eb-b9d9-088047abf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.ioff() #needed so the second time you run it you get only single plo\n",
    "\n",
    "stepsize = 0.5\n",
    "num_steps = 20\n",
    "num_trials = 5\n",
    "\n",
    "final_position = []\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    pos = np.array([0, 0])\n",
    "    path = []\n",
    "    for i in range(num_steps):\n",
    "        pos = pos + np.random.normal(0, stepsize, 2)\n",
    "        path.append(pos)\n",
    "    final_position.append(np.array(path))\n",
    "    \n",
    "x = [final_position[i][:,0] for i in range(len(final_position))]\n",
    "y = [final_position[j][:,1] for j in range(len(final_position))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot()\n",
    "fig.subplots_adjust(left=0.1, right=0.85)\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "def animate(frame):\n",
    "    step_num = frame % (num_steps)\n",
    "    trial_num = frame//(num_steps)\n",
    "    color = cmap(trial_num % 10)\n",
    "    if step_num == num_steps-1:\n",
    "        label = f\"Trial = {trial_num+1}\"\n",
    "    else:\n",
    "        label = None\n",
    "    ax.plot(x[trial_num][:step_num], y[trial_num][:step_num], color = color, ls = '-',linewidth = 0.5,\n",
    "            marker = 'o', ms = 8, mfc = color, mec ='k', zorder = trial_num, label = label)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f\"Number of trials = {trial_num+1} \\nNumber of steps = {step_num+1}\")  \n",
    "    if step_num == num_steps-1:\n",
    "        ax.legend(fontsize=10, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "fig.suptitle(f\"2D random walk simulation for {num_steps} steps over {num_trials} trials.\")\n",
    "ani = FuncAnimation(fig, animate, frames= np.arange(0, (num_steps * num_trials)), interval = 100, repeat = False)\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb6364-c25b-4b68-bc7e-5f5d71051b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If upon first running, it shows a non-interactive, single static shot of the plot below the interactive one with the widget controller,\n",
    "# JUST RE-RUN TWICE. Re-run usually fixes that display quirk.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "#plt.ioff() #needed so the second time you run it you get only single plot\n",
    "import collections\n",
    "import time\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = plt.axes(xlim=(0, 320), ylim=(-1.75, 1.75))\n",
    "lineplot, = ax.plot([], [], \"r-\")\n",
    "lineplot2, = ax.plot([], [], \"b-\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "TIME_STEP = 10      # rnn time step\n",
    "INPUT_SIZE = 1      # rnn input size\n",
    "LR = 0.02           # learning rate\n",
    "\n",
    "# data\n",
    "steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor\n",
    "x_np = np.sin(steps)\n",
    "y_np = np.cos(steps)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,     # rnn hidden unit\n",
    "            num_layers=1,       # number of rnn layer\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "\n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "\n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # outs = outs.view(-1, TIME_STEP, 1)\n",
    "        # return outs, h_state\n",
    "        \n",
    "        # or even simpler, since nn.Linear can accept inputs of any dimension \n",
    "        # and returns outputs with same dimension except for the last\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "h_state = None      # for initial hidden state\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "    \n",
    "def init():\n",
    "    global h_state, data \n",
    "    lineplot.set_data([], [])\n",
    "    lineplot2.set_data([], [])\n",
    "    data = collections.defaultdict(list)\n",
    "    return lineplot, #return [lineplot] also works like in https://nbviewer.org/github/raphaelquast/jupyter_notebook_intro/blob/master/jupyter_nb_introduction.ipynb#pre-render-animations-and-export-to-HTML\n",
    "\n",
    "def animate(i):\n",
    "    global h_state, data \n",
    "    step = i\n",
    "    start, end = step * np.pi, (step+1)*np.pi   # time range\n",
    "    # use sin predicts cos\n",
    "    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32, endpoint=False)  # float32 for converting torch FloatTensor\n",
    "    x_np = np.sin(steps)\n",
    "    y_np = np.cos(steps)\n",
    "\n",
    "    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])    # shape (batch, time_step, input_size)\n",
    "    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])\n",
    "\n",
    "    prediction, h_state = rnn(x, h_state)   # rnn output\n",
    "    # !! next step is important !!\n",
    "    h_state = h_state.data        # repack the hidden state, break the connection from last iteration\n",
    "\n",
    "    loss = loss_func(prediction, y)         # calculate loss\n",
    "    optimizer.zero_grad()                   # clear gradients for this training step\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients\n",
    "\n",
    "    # plotting\n",
    "    data['steps'].append(list(steps))\n",
    "    data['r'].append(y_np.flatten())\n",
    "    data['b'].append(prediction.data.numpy().flatten())\n",
    "    #lineplot.set_data([x], [y])\n",
    "    #lineplot2.set_data([x], [z])\n",
    "    lineplot.set_data(data[\"steps\"],data[\"r\"])\n",
    "    lineplot2.set_data(data[\"steps\"],data[\"b\"])\n",
    "    '''\n",
    "    for i,_ in enumerate(data_dict[\"steps\"]):\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"r\"][i]) , 'r-', )\n",
    "        plt.plot(data_dict[\"steps\"][i], list(data_dict[\"b\"][i]) , 'b-', )\n",
    "    '''\n",
    "    return [lineplot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                           frames=100, interval=20, blit=True)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961c9a2-0adc-4a62-8814-0bbd71126d7b",
   "metadata": {},
   "source": [
    "Manually scrubbing back and forth with the slider allows you to choose a point in the building of the plot.\n",
    "\n",
    "Note, that for some reason I've seen it break the widget normal looping ability at this time. I'm not sure what I did to break it. Manually scrubbing back and forth with the slider did still work even when that happend. I don't know what I broke to make the one above not loop? I tried adding to `init()` and that didn't seem to help. In fact when it broke it, **it would also break it for the one below that is simpler below**. Weird\n",
    "\n",
    "I had seen the glitch I saw was not simply due to including multiple lines because this related, simple code one works to keep looping IN A SEPARATE, or new, NOTEBOOK: (It may or may not work here after running the one above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcce494-86e4-4eec-a4ab-c39a8ae2c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If upon first running, it shows a non-interactive, single static shot of the plot below the interactive one with the widget controller,\n",
    "# JUST RE-RUN TWICE. Re-run usually fixes that display quirk.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.ioff() #needed so the second time you run it you get only single plot\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 4), ylim=(-2, 2))\n",
    "lineplot, = ax.plot([], [], lw=3)\n",
    "lineplot2, = ax.plot([], [], \"r-\")\n",
    "    \n",
    "def init():\n",
    "    lineplot.set_data([], [])\n",
    "    return lineplot, #return [lineplot] also works like in https://nbviewer.org/github/raphaelquast/jupyter_notebook_intro/blob/master/jupyter_nb_introduction.ipynb#pre-render-animations-and-export-to-HTML\n",
    "\n",
    "def animate(i):\n",
    "    x = np.linspace(0, 4, 1000)\n",
    "    y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "    z = np.sin(2.2 * np.pi * (x - 0.31 * i))\n",
    "    lineplot.set_data([x], [y])\n",
    "    lineplot2.set_data([x], [z])\n",
    "    return [lineplot,lineplot2]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                           frames=200, interval=20, blit=True)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15038a30-1203-4ed2-832f-ae076e0119af",
   "metadata": {},
   "source": [
    "More notes on that approach with the widget player controller * `animation.FuncAnimation()`:  \n",
    "Sometimes `plt.ioff()` isn't needed; howver, if you are seeing an empty plot or the final frame show up in addition to the one with the slider then try including it.\n",
    "\n",
    "Unlike the earlier methods demonstrated above in this notebook that play through and don't let you 'pause' at specific points, with the widget controller **you can 'scrub' back and forth to chose points to highlight**. Importantly, **the animation remains playable when the notebook is viewed in a static render at nbviewer**, as [this static view of that notebook](https://nbviewer.org/gist/fomightez/d862333d8eefb94a74a79022840680b1) demonstrates; there is no need for actively running the notebook, unlike the animations produced by the cells above. (GitHub's notebook viewer does not presently support that; you must use [nbviewer](https://nbviewer.jupyter.org/). A variation on that process that produces the widget controller can also produce a portable HTML5 video animation file that can be embedded elsewhere. Indeed, a related [example here](https://stackoverflow.com/a/70764815/8508004) is set up to make such an HTML5 video and has a line that can be uncommented for saving a file version of the video. Making the HTML5 is also covered in [a post by Louis Tiao](https://web.archive.org/web/20230330131423/http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/). (Presently, ffmpeg is not installed and so trying to run [the current code](https://stackoverflow.com/a/70764815/8508004) in sessions here results in `RuntimeError: Requested MovieWriter (ffmpeg) not available`. The last three lines can be deleted and then the animation will be shown with no widget.  Alternatively, running in the active session `%conda install ffmpeg` and then restarting the kernel will allow that notebook to save a portable file version of the video.)  \n",
    "In regards to running the animation with no widget, I also have made comments below a 'animation.FuncAnimation' example [describing how to run that answer code](https://stackoverflow.com/questions/75389311/plotting-a-live-graph-using-matplotlib#comment133024683_75389468) in this session or even in Spyder (using Qt).\n",
    "\n",
    "Note if you are seeing evidence of overdrawing \"causing thick lines and \"blocky\" texts\" or \"Distorted tick labels\" when using `ArtistAnimation` aor `FuncAnimation`, see [here](https://stackoverflow.com/q/65654880/8508004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44f420-4895-40f1-ac88-a2f206ee82a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
